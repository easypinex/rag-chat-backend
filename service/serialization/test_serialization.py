"""
Serialization æ¨¡çµ„æ¸¬è©¦

ç°¡å–®çš„æ¸¬è©¦è…³æœ¬ä¾†é©—è­‰åºåˆ—åŒ–å’Œååºåˆ—åŒ–åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚
"""

import os
import tempfile
from pathlib import Path
from service.markdown_integrate.data_models import ConversionResult, ConversionMetadata, PageInfo, TableInfo
from service.serialization import ConversionSerializer, ConversionDeserializer


def test_basic_serialization():
    """æ¸¬è©¦åŸºæœ¬åºåˆ—åŒ–å’Œååºåˆ—åŒ–åŠŸèƒ½"""
    print("æ¸¬è©¦åŸºæœ¬åºåˆ—åŒ–å’Œååºåˆ—åŒ–...")
    
    # å‰µå»ºæ¸¬è©¦æ•¸æ“š
    metadata = ConversionMetadata(
        file_name="test_document.pdf",
        file_path="/test/path/test_document.pdf",
        file_type=".pdf",
        file_size=1024,
        total_pages=2,
        total_tables=1,
        total_content_length=500,
        conversion_timestamp=1234567890.0,
        converter_used="marker"
    )
    
    # å‰µå»ºæ¸¬è©¦é é¢
    page1 = PageInfo(
        page_number=1,
        title="Test Page 1",
        content="# Test Page 1\n\nThis is test content.",
        content_length=50,
        block_count=2,
        block_types={"header": 1, "paragraph": 1},
        table_count=1,
        tables=[
            TableInfo(
                table_id="table_1",
                title="Test Table",
                content="| A | B |\n|---|---|\n| 1 | 2 |",
                row_count=2,
                column_count=2,
                start_line=5,
                end_line=7
            )
        ]
    )
    
    page2 = PageInfo(
        page_number=2,
        title="Test Page 2",
        content="# Test Page 2\n\nMore test content.",
        content_length=40,
        block_count=2,
        block_types={"header": 1, "paragraph": 1},
        table_count=0,
        tables=[]
    )
    
    # å‰µå»º ConversionResult
    conversion_result = ConversionResult(
        content="# Test Page 1\n\nThis is test content.\n\n# Test Page 2\n\nMore test content.",
        metadata=metadata,
        pages=[page1, page2],
        output_path="/test/output.md"
    )
    
    # ä½¿ç”¨è‡¨æ™‚ç›®éŒ„é€²è¡Œæ¸¬è©¦
    with tempfile.TemporaryDirectory() as temp_dir:
        # åºåˆ—åŒ–
        serializer = ConversionSerializer(output_dir=temp_dir)
        json_path = serializer.serialize(conversion_result, "test_conversion.json")
        
        print(f"âœ“ åºåˆ—åŒ–å®Œæˆ: {json_path}")
        
        # é©—è­‰æ–‡ä»¶å­˜åœ¨
        assert os.path.exists(json_path), "åºåˆ—åŒ–æ–‡ä»¶ä¸å­˜åœ¨"
        print("âœ“ åºåˆ—åŒ–æ–‡ä»¶å­˜åœ¨")
        
        # ååºåˆ—åŒ–
        deserializer = ConversionDeserializer(input_dir=temp_dir)
        restored_result = deserializer.deserialize(json_path)
        
        print("âœ“ ååºåˆ—åŒ–å®Œæˆ")
        
        # é©—è­‰åŸºæœ¬å±¬æ€§
        assert restored_result.content == conversion_result.content, "å…§å®¹ä¸åŒ¹é…"
        assert restored_result.metadata.file_name == conversion_result.metadata.file_name, "æ–‡ä»¶åä¸åŒ¹é…"
        assert restored_result.metadata.total_pages == conversion_result.metadata.total_pages, "ç¸½é æ•¸ä¸åŒ¹é…"
        assert len(restored_result.pages) == len(conversion_result.pages), "é é¢æ•¸é‡ä¸åŒ¹é…"
        
        print("âœ“ åŸºæœ¬å±¬æ€§é©—è­‰é€šé")
        
        # é©—è­‰é é¢ä¿¡æ¯
        for i, (original_page, restored_page) in enumerate(zip(conversion_result.pages, restored_result.pages)):
            assert original_page.page_number == restored_page.page_number, f"é é¢ {i} é ç¢¼ä¸åŒ¹é…"
            assert original_page.title == restored_page.title, f"é é¢ {i} æ¨™é¡Œä¸åŒ¹é…"
            assert original_page.content == restored_page.content, f"é é¢ {i} å…§å®¹ä¸åŒ¹é…"
            assert len(original_page.tables) == len(restored_page.tables), f"é é¢ {i} è¡¨æ ¼æ•¸é‡ä¸åŒ¹é…"
        
        print("âœ“ é é¢ä¿¡æ¯é©—è­‰é€šé")
        
        # é©—è­‰è¡¨æ ¼ä¿¡æ¯
        for i, (original_table, restored_table) in enumerate(zip(conversion_result.pages[0].tables, restored_result.pages[0].tables)):
            assert original_table.table_id == restored_table.table_id, f"è¡¨æ ¼ {i} ID ä¸åŒ¹é…"
            assert original_table.title == restored_table.title, f"è¡¨æ ¼ {i} æ¨™é¡Œä¸åŒ¹é…"
            assert original_table.content == restored_table.content, f"è¡¨æ ¼ {i} å…§å®¹ä¸åŒ¹é…"
        
        print("âœ“ è¡¨æ ¼ä¿¡æ¯é©—è­‰é€šé")
        
        # æ¸¬è©¦æ–‡ä»¶é©—è­‰
        is_valid = deserializer.validate_file(json_path)
        assert is_valid, "æ–‡ä»¶é©—è­‰å¤±æ•—"
        print("âœ“ æ–‡ä»¶é©—è­‰é€šé")
        
        # æ¸¬è©¦æ–‡ä»¶ä¿¡æ¯ç²å–
        file_info = deserializer.get_file_info(json_path)
        assert file_info['original_file_name'] == "test_document.pdf", "æ–‡ä»¶ä¿¡æ¯ä¸æ­£ç¢º"
        print("âœ“ æ–‡ä»¶ä¿¡æ¯ç²å–æˆåŠŸ")
        
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼")


def test_chunk_splitter_integration():
    """æ¸¬è©¦èˆ‡ ChunkSplitter çš„æ•´åˆ"""
    print("\næ¸¬è©¦èˆ‡ ChunkSplitter çš„æ•´åˆ...")
    
    try:
        from service.chunk.chunk_splitter import ChunkSplitter
        
        # å‰µå»ºæ¸¬è©¦æ•¸æ“š
        metadata = ConversionMetadata(
            file_name="integration_test.pdf",
            file_path="/test/integration_test.pdf",
            file_type=".pdf",
            file_size=2048,
            total_pages=1,
            total_tables=0,
            total_content_length=200,
            conversion_timestamp=1234567890.0,
            converter_used="marker"
        )
        
        page = PageInfo(
            page_number=1,
            title="Integration Test",
            content="# Integration Test\n\nThis is a test for chunk splitting integration.\n\n## Section 1\n\nContent for section 1.\n\n## Section 2\n\nContent for section 2.",
            content_length=150,
            block_count=5,
            block_types={"header": 3, "paragraph": 2},
            table_count=0,
            tables=[]
        )
        
        conversion_result = ConversionResult(
            content="# Integration Test\n\nThis is a test for chunk splitting integration.\n\n## Section 1\n\nContent for section 1.\n\n## Section 2\n\nContent for section 2.",
            metadata=metadata,
            pages=[page],
            output_path="/test/integration_output.md"
        )
        
        # ä½¿ç”¨è‡¨æ™‚ç›®éŒ„é€²è¡Œæ¸¬è©¦
        with tempfile.TemporaryDirectory() as temp_dir:
            # åºåˆ—åŒ–
            serializer = ConversionSerializer(output_dir=temp_dir)
            json_path = serializer.serialize(conversion_result, "integration_test.json")
            
            print(f"âœ“ åºåˆ—åŒ–å®Œæˆ: {json_path}")
            
            # ä½¿ç”¨ ChunkSplitter å¾åºåˆ—åŒ–æ–‡ä»¶åˆ†å‰²
            splitter = ChunkSplitter(chunk_size=100, chunk_overlap=20)
            chunks = splitter.split_markdown(
                input_data=json_path,
                from_serialization=True
            )
            
            print(f"âœ“ åˆ†å‰²å®Œæˆï¼Œç”¢ç”Ÿ {len(chunks)} å€‹ chunks")
            
            # é©—è­‰ chunks
            assert len(chunks) > 0, "æ²’æœ‰ç”¢ç”Ÿä»»ä½• chunks"
            
            # æª¢æŸ¥ç¬¬ä¸€å€‹ chunk çš„ metadata
            first_chunk = chunks[0]
            assert first_chunk.metadata.get('file_name') == "integration_test.pdf", "æ–‡ä»¶åä¸æ­£ç¢º"
            assert first_chunk.metadata.get('page_number') == 1, "é ç¢¼ä¸æ­£ç¢º"
            assert first_chunk.metadata.get('page_title') == "Integration Test", "é é¢æ¨™é¡Œä¸æ­£ç¢º"
            
            print("âœ“ Chunk metadata é©—è­‰é€šé")
            print("ğŸ‰ ChunkSplitter æ•´åˆæ¸¬è©¦é€šéï¼")
            
    except ImportError as e:
        print(f"âš ï¸ ç„¡æ³•å°å…¥ ChunkSplitter: {e}")
        print("è·³é ChunkSplitter æ•´åˆæ¸¬è©¦")


def main():
    """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
    print("Serialization æ¨¡çµ„æ¸¬è©¦")
    print("=" * 40)
    
    try:
        test_basic_serialization()
        test_chunk_splitter_integration()
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
