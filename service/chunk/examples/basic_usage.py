#!/usr/bin/env python3
"""
Chunk åˆ†å‰²å™¨åŸºæœ¬ä½¿ç”¨ç¯„ä¾‹

é€™å€‹ç¯„ä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨ ChunkSplitter ä¾†åˆ†å‰² PDF æ–‡ä»¶ã€‚
"""

import sys
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from service.chunk import ChunkSplitter
from service.markdown_integrate import UnifiedMarkdownConverter
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

def main():
    """åŸºæœ¬ä½¿ç”¨ç¯„ä¾‹"""
    print("=== Chunk åˆ†å‰²å™¨åŸºæœ¬ä½¿ç”¨ç¯„ä¾‹ ===\n")
    
    # 1. æº–å‚™è¼¸å…¥æ–‡ä»¶
    pdf_file = "raw_docs/old_version/å°ç£äººå£½ç¾å¹´æœ‰é‘«ç¾å…ƒåˆ©ç‡è®Šå‹•å‹é‚„æœ¬çµ‚èº«ä¿éšª.pdf"
    
    if not Path(pdf_file).exists():
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {pdf_file}")
        print("è«‹ç¢ºä¿æ–‡ä»¶å­˜åœ¨æ–¼æŒ‡å®šè·¯å¾‘")
        return
    
    print(f"ğŸ“„ è¼¸å…¥æ–‡ä»¶: {pdf_file}")
    
    # 2. è½‰æ› PDF åˆ° Markdown
    print("\nğŸ”„ æ­¥é©Ÿ 1: è½‰æ› PDF åˆ° Markdown")
    converter = UnifiedMarkdownConverter()
    result = converter.convert_file(pdf_file)
    
    print(f"âœ… è½‰æ›å®Œæˆ")
    print(f"   - ç¸½é æ•¸: {result.metadata.total_pages}")
    print(f"   - ç¸½è¡¨æ ¼æ•¸: {result.metadata.total_tables}")
    print(f"   - è½‰æ›å™¨: {result.metadata.converter_used}")
    
    # 3. åˆ†å‰² Markdown å…§å®¹
    print("\nâœ‚ï¸ æ­¥é©Ÿ 2: åˆ†å‰² Markdown å…§å®¹")
    
    # å‰µå»ºåˆ†å‰²å™¨
    splitter = ChunkSplitter(
        chunk_size=1000,           # æ¯å€‹ chunk çš„æœ€å¤§å­—ç¬¦æ•¸
        chunk_overlap=200,         # chunk ä¹‹é–“çš„é‡ç–Šå­—ç¬¦æ•¸
        normalize_output=True,     # å•Ÿç”¨å…§å®¹æ­£è¦åŒ–
        keep_tables_together=True  # ä¿æŒè¡¨æ ¼å®Œæ•´æ€§
    )
    
    # åˆ†å‰²å…§å®¹
    chunks = splitter.split_markdown(
        input_data=result,
        output_excel=True,         # è¼¸å‡º Excel æ–‡ä»¶
        output_path="service/output/chunk/basic_example.xlsx",
        md_output_path="service/output/md/basic_example.md"
    )
    
    print(f"âœ… åˆ†å‰²å®Œæˆ: å…± {len(chunks)} å€‹ chunks")
    
    # 4. åˆ†æçµæœ
    print("\nğŸ“Š æ­¥é©Ÿ 3: åˆ†æçµæœ")
    
    # çµ±è¨ˆä¿¡æ¯
    total_length = sum(len(chunk.page_content) for chunk in chunks)
    avg_length = total_length / len(chunks) if chunks else 0
    
    table_chunks = [chunk for chunk in chunks if chunk.metadata.get('is_table', False)]
    
    print(f"   - ç¸½ chunks: {len(chunks)}")
    print(f"   - ç¸½å­—ç¬¦æ•¸: {total_length}")
    print(f"   - å¹³å‡é•·åº¦: {avg_length:.1f}")
    print(f"   - è¡¨æ ¼ chunks: {len(table_chunks)}")
    print(f"   - ä¸€èˆ¬ chunks: {len(chunks) - len(table_chunks)}")
    
    # é ç¢¼åˆ†å¸ƒ
    page_numbers = [chunk.metadata.get('page_number') for chunk in chunks if chunk.metadata.get('page_number')]
    if page_numbers:
        unique_pages = len(set(page_numbers))
        print(f"   - é ç¢¼è¦†è“‹: {unique_pages} é ")
    
    # 5. é¡¯ç¤ºå‰å¹¾å€‹ chunks
    print("\nğŸ“ æ­¥é©Ÿ 4: å‰ 3 å€‹ Chunks é è¦½")
    for i, chunk in enumerate(chunks[:3], 1):
        print(f"\n--- Chunk {i} ---")
        print(f"é•·åº¦: {len(chunk.page_content)}")
        print(f"é ç¢¼: {chunk.metadata.get('page_number', 'N/A')}")
        print(f"æ¨™é¡Œç´šæ•¸: {chunk.metadata.get('Header 1', 'N/A')}")
        print(f"å…§å®¹é è¦½: {chunk.page_content[:100]}...")
    
    print(f"\nğŸ‰ ç¯„ä¾‹å®Œæˆï¼")
    print(f"ğŸ“ Excel æ–‡ä»¶: service/output/chunk/basic_example.xlsx")
    print(f"ğŸ“ Markdown æ–‡ä»¶: service/output/md/basic_example.md")

if __name__ == "__main__":
    main()
