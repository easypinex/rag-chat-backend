"""
Retriever æ•´åˆç¯„ä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ HierarchicalChunkSplitter èˆ‡ LangChain ParentDocumentRetriever æ•´åˆã€‚

é‡è¦ï¼šParentDocumentRetriever çš„æ­£ç¢ºå·¥ä½œæµç¨‹ï¼š
1. ä½¿ç”¨ child chunks é€²è¡Œå‘é‡æª¢ç´¢ï¼ˆæ›´ç²¾ç¢ºçš„åŒ¹é…ï¼‰
2. å°æª¢ç´¢åˆ°çš„ child chunks é€²è¡Œ rerankï¼ˆæé«˜ç›¸é—œæ€§ï¼‰
3. æ ¹æ“š rerank å¾Œçš„ child chunks æ‰¾å‡ºå°æ‡‰çš„ parent chunks
4. å°‡ parent chunks å‚³éçµ¦ LLMï¼ˆä¿æŒå®Œæ•´ä¸Šä¸‹æ–‡ï¼‰
"""

import sys
import logging
from pathlib import Path
from typing import List, Tuple, Optional

# æ·»åŠ è·¯å¾‘åˆ° Python è·¯å¾‘
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent.parent
sys.path.insert(0, str(project_root))

from service.chunk.hierarchical_splitter import HierarchicalChunkSplitter
from service.chunk.hierarchical_models import HierarchicalSplitResult

# å˜—è©¦å°å…¥ LangChain ç›¸é—œå¥—ä»¶
try:
    from langchain_core.documents import Document
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    Document = None

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class HierarchicalRetriever:
    """æ•´åˆ HierarchicalChunkSplitter èˆ‡ ParentDocumentRetriever çš„åŒ…è£é¡"""
    
    def __init__(self, 
                 parent_chunk_size: int = 2000,      # é è¨­å€¼ï¼Œé©åˆä¸­æ–‡32k embedding
                 child_chunk_size: int = 350,        # é è¨­å€¼ï¼Œç´„100-150 tokensï¼Œé©åˆä¸­æ–‡rerank 512
                 child_chunk_overlap: int = 50,       # é è¨­å€¼ï¼Œä¿æŒä¸­æ–‡èªç¾©é€£è²«æ€§
                 embedding_model: str = "BAAI/bge-small-en-v1.5",
                 rerank_model: str = "BAAI/bge-reranker-large"):
        """
        åˆå§‹åŒ–åˆ†å±¤æª¢ç´¢å™¨
        
        Args:
            parent_chunk_size: çˆ¶chunkå¤§å°
            child_chunk_size: å­chunkå¤§å°
            child_chunk_overlap: å­chunké‡ç–Š
            embedding_model: åµŒå…¥æ¨¡å‹åç¨±
            rerank_model: é‡æ’åºæ¨¡å‹åç¨±
        """
        self.parent_chunk_size = parent_chunk_size
        self.child_chunk_size = child_chunk_size
        self.child_chunk_overlap = child_chunk_overlap
        
        # åˆå§‹åŒ–åˆ†å±¤åˆ†å‰²å™¨
        self.hierarchical_splitter = HierarchicalChunkSplitter(
            parent_chunk_size=parent_chunk_size,
            child_chunk_size=child_chunk_size,
            child_chunk_overlap=child_chunk_overlap,
            keep_tables_together=True,
            normalize_output=True
        )
        
        # åˆå§‹åŒ–æª¢ç´¢å™¨çµ„ä»¶ï¼ˆæ¨¡æ“¬ï¼Œå¯¦éš›ä½¿ç”¨æ™‚éœ€è¦å®‰è£ç›¸æ‡‰å¥—ä»¶ï¼‰
        self._setup_retriever_components(embedding_model, rerank_model)
        
        logger.info(f"HierarchicalRetriever initialized")
        logger.info(f"Parent chunk size: {parent_chunk_size}, Child chunk size: {child_chunk_size}")
    
    def _setup_retriever_components(self, embedding_model: str, rerank_model: str):
        """è¨­ç½®æª¢ç´¢å™¨çµ„ä»¶ï¼ˆæ¨¡æ“¬ç‰ˆæœ¬ï¼‰"""
        try:
            # å˜—è©¦å°å…¥å¿…è¦çš„å¥—ä»¶
            from langchain.text_splitter import RecursiveCharacterTextSplitter
            from langchain.retrievers import ParentDocumentRetriever
            from langchain.storage import InMemoryStore
            from langchain_community.vectorstores import FAISS
            from langchain_community.embeddings import HuggingFaceBgeEmbeddings
            from sentence_transformers import CrossEncoder
            from langchain_core.documents import Document
            
            # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
            self.embeddings = HuggingFaceBgeEmbeddings(model_name=embedding_model)
            self.vectorstore = FAISS.from_texts(["dummy"], embedding=self.embeddings)
            self.store = InMemoryStore()
            
            # åˆå§‹åŒ–åˆ†å‰²å™¨
            self.child_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.child_chunk_size, 
                chunk_overlap=self.child_chunk_overlap
            )
            self.parent_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.parent_chunk_size, 
                chunk_overlap=200  # ä½¿ç”¨é è¨­å€¼
            )
            
            # åˆå§‹åŒ– ParentDocumentRetriever
            self.retriever = ParentDocumentRetriever(
                vectorstore=self.vectorstore.as_retriever(search_kwargs={"k": 50}),
                docstore=self.store,
                child_splitter=self.child_splitter,
                parent_splitter=self.parent_splitter
            )
            
            # åˆå§‹åŒ–é‡æ’åºå™¨
            self.reranker = CrossEncoder(rerank_model, max_length=512)
            
            logger.info("âœ“ Retriever components initialized successfully")
            
        except ImportError as e:
            logger.warning(f"âš  ç„¡æ³•å°å…¥æª¢ç´¢å™¨å¥—ä»¶: {e}")
            logger.warning("è«‹å®‰è£: pip install langchain langchain-community sentence-transformers transformers")
            self.retriever = None
            self.reranker = None
    
    def add_documents_from_file(self, file_path: str) -> Optional[HierarchicalSplitResult]:
        """å¾æ–‡ä»¶æ·»åŠ æ–‡æª”åˆ°æª¢ç´¢å™¨"""
        try:
            logger.info(f"Processing file: {file_path}")
            
            # ä½¿ç”¨åˆ†å±¤åˆ†å‰²å™¨è™•ç†æ–‡ä»¶
            result = self.hierarchical_splitter.split_hierarchically(file_path)
            
            if not self.retriever:
                logger.warning("æª¢ç´¢å™¨æœªåˆå§‹åŒ–ï¼Œè·³éæ·»åŠ æ–‡æª”")
                return result
            
            # æº–å‚™æ–‡æª” - ParentDocumentRetriever éœ€è¦æ­£ç¢ºçš„çˆ¶å­é—œä¿‚
            parent_documents = []
            child_documents = []
            
            # æº–å‚™çˆ¶æ–‡æª”
            for parent_chunk in result.parent_chunks:
                if not LANGCHAIN_AVAILABLE:
                    logger.warning("LangChain ä¸å¯ç”¨ï¼Œè·³éæ–‡æª”æº–å‚™")
                    return result
                parent_doc = Document(
                    page_content=parent_chunk.document.page_content,
                    metadata={
                        **parent_chunk.document.metadata,
                        "chunk_id": parent_chunk.chunk_id,
                        "chunk_type": "parent"
                    }
                )
                parent_documents.append(parent_doc)
            
            # æº–å‚™å­æ–‡æª”
            for child_chunk in result.child_chunks:
                child_doc = Document(
                    page_content=child_chunk.document.page_content,
                    metadata={
                        **child_chunk.document.metadata,
                        "chunk_id": child_chunk.chunk_id,
                        "parent_id": child_chunk.parent_chunk_id,
                        "chunk_type": "child"
                    }
                )
                child_documents.append(child_doc)
            
            # æ·»åŠ åˆ°æª¢ç´¢å™¨ï¼ˆParentDocumentRetriever æœƒè‡ªå‹•è™•ç†çˆ¶å­é—œä¿‚ï¼‰
            self.retriever.add_documents(parent_documents)
            
            logger.info(f"âœ“ Added {len(parent_documents)} parent documents to retriever")
            return result
            
        except Exception as e:
            logger.error(f"æ·»åŠ æ–‡æª”å¤±æ•—: {e}")
            return None
    
    def retrieve_with_rerank(self, query: str, top_k: int = 8) -> Tuple[List, List]:
        """æª¢ç´¢ä¸¦é‡æ’åº - ä½¿ç”¨ child chunks é€²è¡Œæª¢ç´¢å’Œ rerank"""
        if not self.retriever or not self.reranker:
            logger.warning("æª¢ç´¢å™¨æˆ–é‡æ’åºå™¨æœªåˆå§‹åŒ–")
            return [], []
        
        try:
            # æ­¥é©Ÿ1: ä½¿ç”¨ child chunks é€²è¡Œå‘é‡æª¢ç´¢ï¼ˆæ›´ç²¾ç¢ºçš„åŒ¹é…ï¼‰
            child_docs = self.retriever.vectorstore.similarity_search(query, k=50)
            logger.info(f"Retrieved {len(child_docs)} child documents")
            
            # æ­¥é©Ÿ2: ä½¿ç”¨ Cross-Encoder å° child chunks é€²è¡Œé‡æ’åº
            pairs = [(query, d.page_content) for d in child_docs]
            scores = self.reranker.predict(pairs)
            ranked = sorted(zip(child_docs, scores), key=lambda x: x[1], reverse=True)
            top_child_docs = [d for d, _ in ranked[:top_k]]
            
            logger.info(f"Reranked to top {len(top_child_docs)} child documents")
            
            # æ­¥é©Ÿ3: æ ¹æ“š rerank å¾Œçš„ child chunks ç²å–å°æ‡‰çš„çˆ¶æ–‡æª”
            parent_docs = []
            for child_doc in top_child_docs:
                parent_id = child_doc.metadata.get("parent_id")
                if parent_id:
                    parent_doc = self.store.mget([parent_id])
                    if parent_doc and parent_doc[0]:
                        parent_docs.append(parent_doc[0])
            
            logger.info(f"Retrieved {len(parent_docs)} parent documents")
            return parent_docs, top_child_docs
            
        except Exception as e:
            logger.error(f"æª¢ç´¢å¤±æ•—: {e}")
            return [], []
    
    def get_retrieval_stats(self) -> dict:
        """ç²å–æª¢ç´¢çµ±è¨ˆä¿¡æ¯"""
        if not self.retriever:
            return {"status": "retriever_not_initialized"}
        
        try:
            # ç²å–å‘é‡åº«çµ±è¨ˆ
            vectorstore_size = len(self.vectorstore.index_to_docstore_id)
            store_size = len(self.store.yield_keys())
            
            return {
                "vectorstore_documents": vectorstore_size,
                "docstore_documents": store_size,
                "status": "ready"
            }
        except Exception as e:
            return {"status": f"error: {e}"}


def example_basic_integration():
    """ç¯„ä¾‹ï¼šåŸºæœ¬æ•´åˆä½¿ç”¨"""
    logger.info("=== åŸºæœ¬æ•´åˆç¯„ä¾‹ ===")
    
    try:
        # å‰µå»ºåˆ†å±¤æª¢ç´¢å™¨ï¼ˆä½¿ç”¨é è¨­å€¼ï¼‰
        retriever = HierarchicalRetriever()
        
        # æ¸¬è©¦æ–‡ä»¶
        test_file = project_root / "raw_docs" / "ç†è³ å¯©æ ¸åŸå‰‡.xlsx"
        
        if not test_file.exists():
            logger.warning(f"æ¸¬è©¦æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
            return False
        
        # æ·»åŠ æ–‡æª”
        result = retriever.add_documents_from_file(str(test_file))
        
        if result:
            logger.info(f"âœ“ æ–‡æª”è™•ç†å®Œæˆ:")
            logger.info(f"- çˆ¶chunks: {len(result.parent_chunks)}")
            logger.info(f"- å­chunks: {len(result.child_chunks)}")
            
            # ç²å–æª¢ç´¢çµ±è¨ˆ
            stats = retriever.get_retrieval_stats()
            logger.info(f"æª¢ç´¢å™¨çµ±è¨ˆ: {stats}")
            
            # æ¨¡æ“¬æª¢ç´¢ï¼ˆå¦‚æœæª¢ç´¢å™¨å¯ç”¨ï¼‰
            if retriever.retriever:
                query = "ç†è³ å¯©æ ¸"
                parent_docs, child_docs = retriever.retrieve_with_rerank(query, top_k=3)
                
                if parent_docs:
                    logger.info(f"âœ“ æª¢ç´¢æˆåŠŸ:")
                    logger.info(f"- çˆ¶æ–‡æª”æ•¸é‡: {len(parent_docs)}")
                    logger.info(f"- å­æ–‡æª”æ•¸é‡: {len(child_docs)}")
                    
                    # é¡¯ç¤ºç¬¬ä¸€å€‹çˆ¶æ–‡æª”çš„é è¦½
                    if parent_docs:
                        preview = parent_docs[0].page_content[:200]
                        logger.info(f"ç¬¬ä¸€å€‹çˆ¶æ–‡æª”é è¦½: {preview}...")
                else:
                    logger.info("âš  æª¢ç´¢çµæœç‚ºç©º")
            else:
                logger.info("âš  æª¢ç´¢å™¨ä¸å¯ç”¨ï¼Œè·³éæª¢ç´¢æ¸¬è©¦")
            
            return True
        else:
            logger.error("âœ— æ–‡æª”è™•ç†å¤±æ•—")
            return False
            
    except Exception as e:
        logger.error(f"åŸºæœ¬æ•´åˆç¯„ä¾‹å¤±æ•—: {e}")
        return False


def example_advanced_usage():
    """ç¯„ä¾‹ï¼šé€²éšä½¿ç”¨"""
    logger.info("=== é€²éšä½¿ç”¨ç¯„ä¾‹ ===")
    
    try:
        # å‰µå»ºå¤šå€‹æª¢ç´¢å™¨å¯¦ä¾‹ï¼ˆæ¯”è¼ƒä¸åŒé…ç½®ï¼‰
        retrievers = {
            "default": HierarchicalRetriever(),  # ä½¿ç”¨é è¨­å€¼
            "small": HierarchicalRetriever(
                parent_chunk_size=1500,
                child_chunk_size=250,
                child_chunk_overlap=30
            ),
            "large": HierarchicalRetriever(
                parent_chunk_size=3000,
                child_chunk_size=500,
                child_chunk_overlap=100
            )
        }
        
        # æ¸¬è©¦æ–‡ä»¶
        test_file = project_root / "raw_docs" / "ç†è³ å¯©æ ¸åŸå‰‡.xlsx"
        
        if not test_file.exists():
            logger.warning(f"æ¸¬è©¦æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
            return False
        
        results = {}
        
        # æ¸¬è©¦ä¸åŒé…ç½®
        for name, retriever in retrievers.items():
            logger.info(f"æ¸¬è©¦ {name} é…ç½®...")
            
            result = retriever.add_documents_from_file(str(test_file))
            
            if result:
                results[name] = {
                    "parent_chunks": len(result.parent_chunks),
                    "child_chunks": len(result.child_chunks),
                    "avg_children_per_parent": result.grouping_analysis.avg_children_per_parent,
                    "grouping_efficiency": result.grouping_analysis.grouping_efficiency
                }
                
                logger.info(f"âœ“ {name} é…ç½®å®Œæˆ:")
                logger.info(f"  - çˆ¶chunks: {results[name]['parent_chunks']}")
                logger.info(f"  - å­chunks: {results[name]['child_chunks']}")
                logger.info(f"  - å¹³å‡æ¯çˆ¶chunkçš„å­chunks: {results[name]['avg_children_per_parent']:.2f}")
                logger.info(f"  - åˆ†çµ„æ•ˆç‡: {results[name]['grouping_efficiency']:.2%}")
            else:
                logger.error(f"âœ— {name} é…ç½®å¤±æ•—")
        
        # æ¯”è¼ƒçµæœ
        if results:
            logger.info("=== é…ç½®æ¯”è¼ƒ ===")
            for name, stats in results.items():
                logger.info(f"{name}: æ•ˆç‡={stats['grouping_efficiency']:.2%}, "
                          f"çˆ¶chunks={stats['parent_chunks']}, å­chunks={stats['child_chunks']}")
        
        return len(results) > 0
        
    except Exception as e:
        logger.error(f"é€²éšä½¿ç”¨ç¯„ä¾‹å¤±æ•—: {e}")
        return False


def main():
    """ä¸»ç¨‹å¼"""
    logger.info("é–‹å§‹ Retriever æ•´åˆç¯„ä¾‹...")
    
    # ç¯„ä¾‹1: åŸºæœ¬æ•´åˆ
    logger.info("\n" + "="*50)
    result1 = example_basic_integration()
    
    # ç¯„ä¾‹2: é€²éšä½¿ç”¨
    logger.info("\n" + "="*50)
    result2 = example_advanced_usage()
    
    # é¡¯ç¤ºçµæœæ‘˜è¦
    logger.info("\n" + "="*50)
    logger.info("ç¯„ä¾‹åŸ·è¡Œçµæœ:")
    logger.info(f"- åŸºæœ¬æ•´åˆ: {'âœ“ æˆåŠŸ' if result1 else 'âœ— å¤±æ•—'}")
    logger.info(f"- é€²éšä½¿ç”¨: {'âœ“ æˆåŠŸ' if result2 else 'âœ— å¤±æ•—'}")
    
    if result1 or result2:
        logger.info("ğŸ‰ è‡³å°‘ä¸€å€‹ç¯„ä¾‹åŸ·è¡ŒæˆåŠŸï¼")
    else:
        logger.warning("âš  æ‰€æœ‰ç¯„ä¾‹éƒ½å¤±æ•—äº†ï¼Œè«‹æª¢æŸ¥é…ç½®ã€‚")


if __name__ == "__main__":
    main()
