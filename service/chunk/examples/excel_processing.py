#!/usr/bin/env python3
"""
Excel æ–‡ä»¶è™•ç†ç¯„ä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ ChunkSplitter è™•ç† Excel æ–‡ä»¶ï¼ŒåŒ…æ‹¬æœ‰é é¢çµæ§‹å’Œç„¡é é¢çµæ§‹çš„æƒ…æ³ã€‚
"""

import sys
from pathlib import Path
import logging

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from service.chunk import ChunkSplitter
from service.markdown_integrate import UnifiedMarkdownConverter

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

def process_excel_file():
    """è™•ç† Excel æ–‡ä»¶"""
    print("=== Excel æ–‡ä»¶è™•ç†ç¯„ä¾‹ ===\n")
    
    # 1. æº–å‚™è¼¸å…¥æ–‡ä»¶
    excel_file = "raw_docs/ç†è³ å¯©æ ¸åŸå‰‡.xlsx"
    
    if not Path(excel_file).exists():
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {excel_file}")
        print("è«‹ç¢ºä¿æ–‡ä»¶å­˜åœ¨æ–¼æŒ‡å®šè·¯å¾‘")
        return
    
    print(f"ğŸ“„ è¼¸å…¥æ–‡ä»¶: {excel_file}")
    
    # 2. è½‰æ› Excel åˆ° Markdown
    print("\nğŸ”„ æ­¥é©Ÿ 1: è½‰æ› Excel åˆ° Markdown")
    converter = UnifiedMarkdownConverter()
    result = converter.convert_file(excel_file)
    
    print(f"âœ… è½‰æ›å®Œæˆ")
    print(f"   - æª”å: {result.metadata.file_name}")
    print(f"   - æª”æ¡ˆé¡å‹: {result.metadata.file_type}")
    print(f"   - è½‰æ›å™¨: {result.metadata.converter_used}")
    print(f"   - ç¸½é æ•¸: {result.metadata.total_pages}")
    print(f"   - ç¸½è¡¨æ ¼æ•¸: {result.metadata.total_tables}")
    print(f"   - é é¢ä¿¡æ¯: {'æœ‰' if result.pages and len(result.pages) > 0 else 'ç„¡'}")
    
    # 3. åˆ†å‰² Markdown å…§å®¹
    print("\nâœ‚ï¸ æ­¥é©Ÿ 2: åˆ†å‰² Markdown å…§å®¹")
    
    # å‰µå»ºåˆ†å‰²å™¨
    splitter = ChunkSplitter(
        chunk_size=800,           # è¼ƒå°çš„ chunk å¤§å°
        chunk_overlap=150,        # è¼ƒå°çš„é‡ç–Š
        normalize_output=True,    # å•Ÿç”¨å…§å®¹æ­£è¦åŒ–
        keep_tables_together=True # ä¿æŒè¡¨æ ¼å®Œæ•´æ€§
    )
    
    # åˆ†å‰²å…§å®¹
    chunks = splitter.split_markdown(
        input_data=result,
        output_excel=True,         # è¼¸å‡º Excel æ–‡ä»¶
        output_path="service/output/chunk/excel_processing.xlsx",
        md_output_path="service/output/md/excel_processing.md"
    )
    
    print(f"âœ… åˆ†å‰²å®Œæˆ: å…± {len(chunks)} å€‹ chunks")
    
    # 4. åˆ†æçµæœ
    print("\nğŸ“Š æ­¥é©Ÿ 3: åˆ†æçµæœ")
    
    # åŸºæœ¬çµ±è¨ˆ
    total_length = sum(len(chunk.page_content) for chunk in chunks)
    avg_length = total_length / len(chunks) if chunks else 0
    
    # æª¢æŸ¥é ç¢¼æƒ…æ³
    page_numbers = [chunk.metadata.get('page_number') for chunk in chunks]
    has_page_numbers = any(pn is not None for pn in page_numbers)
    unique_pages = len(set(pn for pn in page_numbers if pn is not None))
    
    # è¡¨æ ¼ chunks
    table_chunks = [chunk for chunk in chunks if chunk.metadata.get('is_table', False)]
    
    print(f"   - ç¸½ chunks: {len(chunks)}")
    print(f"   - ç¸½å­—ç¬¦æ•¸: {total_length}")
    print(f"   - å¹³å‡é•·åº¦: {avg_length:.1f}")
    print(f"   - è¡¨æ ¼ chunks: {len(table_chunks)}")
    print(f"   - ä¸€èˆ¬ chunks: {len(chunks) - len(table_chunks)}")
    print(f"   - é ç¢¼æƒ…æ³: {'æœ‰é ç¢¼' if has_page_numbers else 'ç„¡é ç¢¼'}")
    if has_page_numbers:
        print(f"   - é ç¢¼è¦†è“‹: {unique_pages} é ")
    
    # 5. æª¢æŸ¥åˆ†å‰²æ¨¡å¼
    print("\nğŸ” æ­¥é©Ÿ 4: åˆ†å‰²æ¨¡å¼åˆ†æ")
    if has_page_numbers:
        print("âœ… ä½¿ç”¨åŸºæ–¼é é¢çš„åˆ†å‰²æ¨¡å¼")
        print("   - æ¯å€‹ chunk éƒ½æœ‰æ˜ç¢ºçš„é ç¢¼")
        print("   - åŸå§‹å…§å®¹æŒ‰é é¢åˆ†çµ„")
    else:
        print("âœ… ä½¿ç”¨åŸºæœ¬åˆ†å‰²æ¨¡å¼")
        print("   - ç›´æ¥è™•ç†å®Œæ•´å…§å®¹")
        print("   - æ²’æœ‰é ç¢¼ä¿¡æ¯")
    
    # 6. é¡¯ç¤ºå‰å¹¾å€‹ chunks
    print("\nğŸ“ æ­¥é©Ÿ 5: å‰ 3 å€‹ Chunks é è¦½")
    for i, chunk in enumerate(chunks[:3], 1):
        print(f"\n--- Chunk {i} ---")
        print(f"é•·åº¦: {len(chunk.page_content)}")
        print(f"é ç¢¼: {chunk.metadata.get('page_number', 'N/A')}")
        print(f"æ¨™é¡Œç´šæ•¸: {chunk.metadata.get('Header 1', 'N/A')}")
        print(f"å…§å®¹é è¦½: {chunk.page_content[:100]}...")
    
    print(f"\nğŸ‰ Excel æ–‡ä»¶è™•ç†å®Œæˆï¼")
    print(f"ğŸ“ Excel æ–‡ä»¶: service/output/chunk/excel_processing.xlsx")
    print(f"ğŸ“ Markdown æ–‡ä»¶: service/output/md/excel_processing.md")
    
    return chunks

def analyze_chunk_metadata(chunks):
    """åˆ†æ chunk metadata"""
    print("\n=== Chunk Metadata åˆ†æ ===\n")
    
    if not chunks:
        print("âŒ æ²’æœ‰ chunks å¯åˆ†æ")
        return
    
    # çµ±è¨ˆ metadata æ¬„ä½
    all_metadata_keys = set()
    for chunk in chunks:
        all_metadata_keys.update(chunk.metadata.keys())
    
    print(f"ğŸ“Š Metadata æ¬„ä½çµ±è¨ˆ:")
    for key in sorted(all_metadata_keys):
        count = sum(1 for chunk in chunks if key in chunk.metadata)
        print(f"   - {key}: {count}/{len(chunks)} chunks")
    
    # æª¢æŸ¥é ç¢¼åˆ†å¸ƒ
    page_numbers = [chunk.metadata.get('page_number') for chunk in chunks]
    page_distribution = {}
    for pn in page_numbers:
        if pn is not None:
            page_distribution[pn] = page_distribution.get(pn, 0) + 1
    
    if page_distribution:
        print(f"\nğŸ“„ é ç¢¼åˆ†å¸ƒ:")
        for page_num in sorted(page_distribution.keys()):
            print(f"   - é é¢ {page_num}: {page_distribution[page_num]} å€‹ chunks")
    else:
        print(f"\nğŸ“„ é ç¢¼åˆ†å¸ƒ: ç„¡é ç¢¼ä¿¡æ¯ï¼ˆåŸºæœ¬åˆ†å‰²æ¨¡å¼ï¼‰")
    
    # æª¢æŸ¥æ¨™é¡Œç´šæ•¸åˆ†å¸ƒ
    header_levels = {}
    for chunk in chunks:
        level = get_header_level(chunk.metadata)
        header_levels[level] = header_levels.get(level, 0) + 1
    
    print(f"\nğŸ“‹ æ¨™é¡Œç´šæ•¸åˆ†å¸ƒ:")
    for level in sorted(header_levels.keys()):
        print(f"   - {level}ç´šæ¨™é¡Œ: {header_levels[level]} å€‹ chunks")

def get_header_level(metadata):
    """ç²å–æ¨™é¡Œç´šæ•¸"""
    if 'Header 4' in metadata and metadata['Header 4']:
        return 'å››'
    elif 'Header 3' in metadata and metadata['Header 3']:
        return 'ä¸‰'
    elif 'Header 2' in metadata and metadata['Header 2']:
        return 'äºŒ'
    elif 'Header 1' in metadata and metadata['Header 1']:
        return 'ä¸€'
    else:
        return 'ç„¡'

def main():
    """ä¸»å‡½æ•¸"""
    print("=== Excel æ–‡ä»¶è™•ç†ç¯„ä¾‹ ===\n")
    
    try:
        # è™•ç† Excel æ–‡ä»¶
        chunks = process_excel_file()
        
        if chunks:
            # åˆ†æ metadata
            analyze_chunk_metadata(chunks)
            
            print(f"\nğŸ‰ ç¯„ä¾‹å®Œæˆï¼")
        else:
            print(f"\nâŒ è™•ç†å¤±æ•—")
            
    except Exception as e:
        print(f"\nâŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
