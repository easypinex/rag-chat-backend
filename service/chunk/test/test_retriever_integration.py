"""
Retriever æ•´åˆæ¸¬è©¦

æ¸¬è©¦ HierarchicalChunkSplitter èˆ‡ ParentDocumentRetriever çš„æ•´åˆåŠŸèƒ½ã€‚
"""

import sys
import logging
from pathlib import Path

# æ·»åŠ è·¯å¾‘åˆ° Python è·¯å¾‘
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent
sys.path.insert(0, str(project_root))

from service.chunk.hierarchical_splitter import HierarchicalChunkSplitter
from service.chunk.hierarchical_models import HierarchicalSplitResult

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_hierarchical_splitter():
    """æ¸¬è©¦åˆ†å±¤åˆ†å‰²å™¨åŸºæœ¬åŠŸèƒ½"""
    logger.info("=== æ¸¬è©¦åˆ†å±¤åˆ†å‰²å™¨ ===")
    
    try:
        # å‰µå»ºåˆ†å±¤åˆ†å‰²å™¨
        splitter = HierarchicalChunkSplitter(
            parent_chunk_size=2000,
            child_chunk_size=500,
            child_chunk_overlap=100
        )
        
        logger.info("âœ“ HierarchicalChunkSplitter å‰µå»ºæˆåŠŸ")
        
        # æ¸¬è©¦æ–‡ä»¶
        test_file = project_root / "raw_docs" / "ç†è³ å¯©æ ¸åŸå‰‡.xlsx"
        
        if not test_file.exists():
            logger.warning(f"æ¸¬è©¦æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
            return False
        
        # é€²è¡Œåˆ†å±¤åˆ†å‰²
        result = splitter.split_hierarchically(str(test_file))
        
        logger.info(f"âœ“ åˆ†å±¤åˆ†å‰²å®Œæˆ:")
        logger.info(f"- çˆ¶chunks: {len(result.parent_chunks)}")
        logger.info(f"- å­chunks: {len(result.child_chunks)}")
        logger.info(f"- åˆ†çµ„æ•ˆç‡: {result.grouping_analysis.grouping_efficiency:.2%}")
        
        return True
        
    except Exception as e:
        logger.error(f"âœ— åˆ†å±¤åˆ†å‰²å™¨æ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_data_preparation():
    """æ¸¬è©¦è³‡æ–™æº–å‚™åŠŸèƒ½"""
    logger.info("=== æ¸¬è©¦è³‡æ–™æº–å‚™ ===")
    
    try:
        # å‰µå»ºåˆ†å±¤åˆ†å‰²å™¨
        splitter = HierarchicalChunkSplitter(
            parent_chunk_size=1500,
            child_chunk_size=400,
            child_chunk_overlap=80
        )
        
        # æ¸¬è©¦æ–‡ä»¶
        test_file = project_root / "raw_docs" / "ç†è³ å¯©æ ¸åŸå‰‡.xlsx"
        
        if not test_file.exists():
            logger.warning(f"æ¸¬è©¦æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
            return False
        
        # é€²è¡Œåˆ†å±¤åˆ†å‰²
        result = splitter.split_hierarchically(str(test_file))
        
        # æº–å‚™ ParentDocumentRetriever çš„è³‡æ–™
        documents = []
        for parent_chunk in result.parent_chunks:
            # æ¨¡æ“¬ LangChain Document å‰µå»º
            doc_data = {
                "page_content": parent_chunk.document.page_content,
                "metadata": {
                    **parent_chunk.document.metadata,
                    "chunk_id": parent_chunk.chunk_id,
                    "chunk_type": "parent"
                }
            }
            documents.append(doc_data)
        
        logger.info(f"âœ“ è³‡æ–™æº–å‚™å®Œæˆ:")
        logger.info(f"- æº–å‚™äº† {len(documents)} å€‹æ–‡æª”")
        
        # æª¢æŸ¥æ–‡æª”çµæ§‹
        if documents:
            sample_doc = documents[0]
            logger.info(f"- æ–‡æª”å…§å®¹é•·åº¦: {len(sample_doc['page_content'])}")
            logger.info(f"- å…ƒæ•¸æ“šæ¬„ä½: {list(sample_doc['metadata'].keys())}")
            logger.info(f"- Chunk ID: {sample_doc['metadata'].get('chunk_id')}")
        
        return True
        
    except Exception as e:
        logger.error(f"âœ— è³‡æ–™æº–å‚™æ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_retrieval_simulation():
    """æ¸¬è©¦æª¢ç´¢æ¨¡æ“¬"""
    logger.info("=== æ¸¬è©¦æª¢ç´¢æ¨¡æ“¬ ===")
    
    try:
        # å‰µå»ºåˆ†å±¤åˆ†å‰²å™¨
        splitter = HierarchicalChunkSplitter(
            parent_chunk_size=2000,
            child_chunk_size=600,
            child_chunk_overlap=120
        )
        
        # æ¸¬è©¦æ–‡ä»¶
        test_file = project_root / "raw_docs" / "ç†è³ å¯©æ ¸åŸå‰‡.xlsx"
        
        if not test_file.exists():
            logger.warning(f"æ¸¬è©¦æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
            return False
        
        # é€²è¡Œåˆ†å±¤åˆ†å‰²
        result = splitter.split_hierarchically(str(test_file))
        
        # æ¨¡æ“¬æª¢ç´¢éç¨‹
        query = "ç†è³ å¯©æ ¸"
        
        # æ¨¡æ“¬å­æ–‡æª”æª¢ç´¢ï¼ˆåŸºæ–¼å…§å®¹ç›¸ä¼¼åº¦ï¼‰
        child_docs = []
        for child_chunk in result.child_chunks:
            content = child_chunk.document.page_content.lower()
            if query.lower() in content:
                child_docs.append({
                    "chunk_id": child_chunk.chunk_id,
                    "parent_chunk_id": child_chunk.parent_chunk_id,
                    "content": child_chunk.document.page_content,
                    "size": child_chunk.size,
                    "is_table_chunk": child_chunk.is_table_chunk
                })
        
        logger.info(f"âœ“ æª¢ç´¢æ¨¡æ“¬å®Œæˆ:")
        logger.info(f"- æŸ¥è©¢: '{query}'")
        logger.info(f"- æ‰¾åˆ° {len(child_docs)} å€‹ç›¸é—œå­chunks")
        
        # æ¨¡æ“¬é‡æ’åºï¼ˆæŒ‰å¤§å°æ’åºä½œç‚ºç°¡å–®ç¤ºä¾‹ï¼‰
        child_docs.sort(key=lambda x: x["size"], reverse=True)
        top_k = min(5, len(child_docs))
        top_child_docs = child_docs[:top_k]
        
        logger.info(f"- é‡æ’åºå¾Œå–å‰ {top_k} å€‹")
        
        # æ¨¡æ“¬ç²å–å°æ‡‰çš„çˆ¶æ–‡æª”
        parent_docs = []
        for child_doc in top_child_docs:
            parent_id = child_doc["parent_chunk_id"]
            for parent_chunk in result.parent_chunks:
                if parent_chunk.chunk_id == parent_id:
                    parent_docs.append({
                        "chunk_id": parent_chunk.chunk_id,
                        "content": parent_chunk.document.page_content,
                        "size": parent_chunk.size,
                        "has_tables": parent_chunk.has_tables
                    })
                    break
        
        logger.info(f"- ç²å–åˆ° {len(parent_docs)} å€‹å°æ‡‰çš„çˆ¶chunks")
        
        # é¡¯ç¤ºçµæœæ‘˜è¦
        if parent_docs:
            total_context_size = sum(doc["size"] for doc in parent_docs)
            logger.info(f"- ç¸½ä¸Šä¸‹æ–‡å¤§å°: {total_context_size} å­—")
            
            # é¡¯ç¤ºç¬¬ä¸€å€‹çˆ¶chunkçš„é è¦½
            first_parent = parent_docs[0]
            preview = first_parent["content"][:150]
            logger.info(f"- ç¬¬ä¸€å€‹çˆ¶chunké è¦½: {preview}...")
        
        return True
        
    except Exception as e:
        logger.error(f"âœ— æª¢ç´¢æ¨¡æ“¬æ¸¬è©¦å¤±æ•—: {e}")
        return False


def test_integration_workflow():
    """æ¸¬è©¦å®Œæ•´æ•´åˆå·¥ä½œæµç¨‹"""
    logger.info("=== æ¸¬è©¦å®Œæ•´æ•´åˆå·¥ä½œæµç¨‹ ===")
    
    try:
        # æ­¥é©Ÿ1: å‰µå»ºåˆ†å±¤åˆ†å‰²å™¨
        splitter = HierarchicalChunkSplitter(
            parent_chunk_size=2500,
            child_chunk_size=800,
            child_chunk_overlap=150
        )
        
        # æ­¥é©Ÿ2: è™•ç†æ–‡æª”
        test_file = project_root / "raw_docs" / "ç†è³ å¯©æ ¸åŸå‰‡.xlsx"
        
        if not test_file.exists():
            logger.warning(f"æ¸¬è©¦æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
            return False
        
        result = splitter.split_hierarchically(str(test_file))
        
        # æ­¥é©Ÿ3: æº–å‚™æª¢ç´¢è³‡æ–™
        documents = []
        for parent_chunk in result.parent_chunks:
            doc = {
                "page_content": parent_chunk.document.page_content,
                "metadata": {
                    **parent_chunk.document.metadata,
                    "chunk_id": parent_chunk.chunk_id,
                    "chunk_type": "parent"
                }
            }
            documents.append(doc)
        
        # æ­¥é©Ÿ4: æ¨¡æ“¬æª¢ç´¢æµç¨‹
        queries = ["ç†è³ å¯©æ ¸", "ä¿éšª", "ç”³è«‹"]
        
        for query in queries:
            logger.info(f"è™•ç†æŸ¥è©¢: '{query}'")
            
            # æ¨¡æ“¬æª¢ç´¢
            relevant_docs = []
            for doc in documents:
                if query.lower() in doc["page_content"].lower():
                    relevant_docs.append(doc)
            
            # æ¨¡æ“¬é‡æ’åºï¼ˆæŒ‰å…§å®¹é•·åº¦ï¼‰
            relevant_docs.sort(key=lambda x: len(x["page_content"]), reverse=True)
            top_docs = relevant_docs[:3]  # å–å‰3å€‹
            
            logger.info(f"  - æ‰¾åˆ° {len(relevant_docs)} å€‹ç›¸é—œæ–‡æª”")
            logger.info(f"  - é‡æ’åºå¾Œå–å‰ {len(top_docs)} å€‹")
            
            if top_docs:
                total_size = sum(len(doc["page_content"]) for doc in top_docs)
                logger.info(f"  - ç¸½ä¸Šä¸‹æ–‡å¤§å°: {total_size} å­—")
        
        logger.info("âœ“ å®Œæ•´æ•´åˆå·¥ä½œæµç¨‹æ¸¬è©¦æˆåŠŸ")
        return True
        
    except Exception as e:
        logger.error(f"âœ— å®Œæ•´æ•´åˆå·¥ä½œæµç¨‹æ¸¬è©¦å¤±æ•—: {e}")
        return False


def main():
    """ä¸»æ¸¬è©¦ç¨‹å¼"""
    logger.info("é–‹å§‹ Retriever æ•´åˆæ¸¬è©¦...")
    
    tests = [
        ("åˆ†å±¤åˆ†å‰²å™¨", test_hierarchical_splitter),
        ("è³‡æ–™æº–å‚™", test_data_preparation),
        ("æª¢ç´¢æ¨¡æ“¬", test_retrieval_simulation),
        ("å®Œæ•´å·¥ä½œæµç¨‹", test_integration_workflow)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        logger.info(f"\nåŸ·è¡Œæ¸¬è©¦: {test_name}")
        try:
            result = test_func()
            results.append((test_name, result))
            if result:
                logger.info(f"âœ“ {test_name} æ¸¬è©¦é€šé")
            else:
                logger.error(f"âœ— {test_name} æ¸¬è©¦å¤±æ•—")
        except Exception as e:
            logger.error(f"âœ— {test_name} æ¸¬è©¦ç•°å¸¸: {e}")
            results.append((test_name, False))
    
    # é¡¯ç¤ºæ¸¬è©¦çµæœæ‘˜è¦
    logger.info("\n" + "="*50)
    logger.info("æ¸¬è©¦çµæœæ‘˜è¦:")
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ“ é€šé" if result else "âœ— å¤±æ•—"
        logger.info(f"- {test_name}: {status}")
        if result:
            passed += 1
    
    logger.info(f"\nç¸½è¨ˆ: {passed}/{total} æ¸¬è©¦é€šé")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼Retriever æ•´åˆåŠŸèƒ½å·²æº–å‚™å°±ç·’ã€‚")
    else:
        logger.warning("âš  éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç›¸é—œåŠŸèƒ½ã€‚")


if __name__ == "__main__":
    main()
